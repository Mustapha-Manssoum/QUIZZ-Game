# DÃ©veloppement dâ€™une application web de quiz quâ€™on a nommÃ© QuiTSE.

## Ce projet comporte principalement 3 grandes parties:
	### - Lâ€™entrainement dâ€™un modÃ¨le machine learning Ã  fin quâ€™il reconnaisse des audios 
	### - Le dÃ©veloppement dâ€™une interface utilisateur (Front-End + Back-End)
	### - DÃ©ploiement de lâ€™application dans un cloud AWS avec stockage des donnÃ©es, modÃ¨les et rÃ©ponses dans le cloud aussi.

## Partie 1: ML: ModÃ¨le de reconnaissance vocale:

### speech_recognition.ipynb

On a utilisÃ© pour la reconnaissance vocale le model Â«Â speech_recognitionÂ Â», une bibliothÃ¨que Python qui utilise lâ€™API de Google Speech Recognition.

1 -Le modÃ¨le prend comme entrÃ©e un audio qui sera enregistrer en utilisant le microphone ğŸ™.

-La mÃ©thode listen de l'objet recognizer est utilisÃ©e pour Ã©couter l'audio provenant du microphone. L'objet audio est ensuite transmis Ã  la mÃ©thode recognize_google, qui effectue la reconnaissance de la parole en utilisant Google Speech Recognition et en spÃ©cifiant que la reconnaissance doit Ãªtre effectuÃ©e en franÃ§ais (fr-FR).
-La variable text stocke la rÃ©ponse prononcÃ© par l'utilisateur, qui va Ãªtre comparÃ©e par la suite avec les rÃ©ponses que nous avons dÃ©finie pour notre quizz dans une base de donnÃ©es.

2 -Le modÃ¨le prend comme entrÃ©e un fichier audio .
  - La bibliothÃ¨que librosa fournit par Python, est utilisÃ©e pour charger et traiter des fichiers audio.
  -  La fonction librosa.load est ensuite utilisÃ©e pour charger les donnÃ©es audio et la frÃ©quence d'Ã©chantillonnage Ã  partir du fichier audio dont il faut prÃ©ciser le chemain d'accÃ¨s .
 Par la suite on a utilisÃ© la mÃªme bibliothÃ¨que citÃ© dans la mÃ©thode1: Â Â«Â speech_recognitionÂ Â» pour convertir lâ€™audio en texte.



### Quizz model.ipynb

On a utilisÃ© un script python qui va effectuer le traitement de fichiers audio. Il dÃ©finit deux listes, labels et mfcc_features, pour stocker les Ã©tiquettes et les caractÃ©ristiques MFCC respectivement.

On a utilisÃ©, par la suite, la fonction os.listdir pour parcourir tous les sous-dossiers dans le dossier "new_data". Pour chaque sous-dossier, il parcourt Ã©galement tous les fichiers audio Ã  l'aide de os.listdir. Pour chaque fichier audio, il utilise la bibliothÃ¨que librosa pour charger le fichier audio et extraire les caractÃ©ristiques MFCC.

On a rÃ©partis notre data Ã  train_set et test_set, on a utilisÃ© comme modÃ¨le pour entraÃ®ner la data; SVC (Support Vector Classification) du module sklearn.svm. L'objet entraÃ®nÃ© est stockÃ© dans la variable H. Le modÃ¨le peut maintenant Ãªtre utilisÃ© pour prÃ©dire des labels pour des donnÃ©es de test en utilisant la mÃ©thode predict.

La fonction accuracy_score est utilisÃ©e pour Ã©valuer la prÃ©cision du modÃ¨le en comparant les labels rÃ©elles y_train avec les labels prÃ©dites y_pred. Le score de prÃ©cision est stockÃ© dans la variable train_accuracy. On fait de mÃªme pour data test. 

## Partie 2: DÃ©veloppement de l'interface utilisateur: Back-End + Front-End


## Partie 3: HÃ©bergement Cloud









